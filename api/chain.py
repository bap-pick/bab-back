import re
import random 
from typing import List
from sqlalchemy.orm import Session
import google.genai as genai
from google.genai import types
from langchain_chroma import Chroma
from core.config import GEMMA_API_KEY
from core.models import ChatMessage, Restaurant
from api.saju import _get_oheng_analysis_data
from saju.message_generator import define_oheng_messages
from vectordb.vectordb_util import get_embeddings, get_chroma_client, COLLECTION_NAME_RESTAURANTS

client = genai.Client(api_key=GEMMA_API_KEY)
model_name = "gemma-3-4b-it"

# ì˜¤í–‰ë³„ ìŒì‹ ëª©ë¡
OHAENG_FOOD_LISTS = {
    'ëª©(æœ¨)': [
        "ìƒëŸ¬ë“œ", "ìš”ê±°íŠ¸", "ìŒˆë°¥", "ì›”ë‚¨ìŒˆ",
        "ëœì¥êµ­", "ë¯¸ì—­êµ­", "ë¶€ì¶”ì „", "ë¹„ë¹”ë°¥", "ë¹„ë¹”ë°¥", "ë°”ì§ˆë¦¬ì¡°ë˜",
        "ë£¨ê¼´ë¼í”¼ì", "ê·¸ë¦°ìŠ¤ë¬´ë””", "ë¸Œë¡œì½œë¦¬ë³¶ìŒ", "ì²­ê²½ì±„ë³¶ìŒ"
    ],
    'í™”(ç«)': [
        "ë–¡ë³¶ì´", "ë¡œì œë–¡ë³¶ì´", "ê¹€ì¹˜ì°Œê°œ", "ë¶€ëŒ€ì°Œê°œ", "ë§¤ìš´íƒ•",
        "ì§¬ë½•", "ì œìœ¡ë³¶ìŒ", "ë¶ˆê³ ê¸°ë®ë°¥", "ë‹­ê°ˆë¹„", "ë¶ˆê³ ê¸°", "ì–‘ë…ì¹˜í‚¨",
        "ë‹­ê°•ì •", "í”¼ì", "íŒŒìŠ¤íƒ€",
        "ì»¤ë¦¬", "ê³ ì¶”ì¡ì±„", "ë§ˆíŒŒë‘ë¶€", "ê³ ì¶”íƒ•ìˆ˜ìœ¡", "ì‚¬ì²œì§œì¥", "ì˜¤ì§•ì–´ë³¶ìŒ",
        "ë¼ë³¶ì´", "ë¹„ë¹”êµ­ìˆ˜", "ë‹­ê¼¬ì¹˜", "ìŠ¤í…Œì´í¬", "í•«ë„ê·¸", "ë¦¬ì¡°ë˜",
        "ë¶ˆë‹­ë§ˆìš”ë®ë°¥", "ë² ì´ì»¨ë²„ê±°",  "ë‚˜ì´ˆ"
    ],
    'í† (åœŸ)': [
        "ì„¤ë íƒ•", "ì‚¼ê³„íƒ•", "ê³°íƒ•", "ëœì¥ì°Œê°œ", "ìˆœë‘ë¶€ì°Œê°œ", "ê°ìíƒ•",
        "ì˜¤ë¦¬ë°±ìˆ™", "ë‹­ì£½", "í˜¸ë°•ì£½", "ê°ìì „", "ê°ìíƒ•", "í¬ë¦¼íŒŒìŠ¤íƒ€",
        "í¬ë¦¼ë¦¬ì¡°ë˜", "ì¹´ë ˆë¼ì´ìŠ¤", "ì˜¤ë¯€ë¼ì´ìŠ¤", "í•¨ë°•ìŠ¤í…Œì´í¬", "ìŠ¤í…Œì´í¬ë®ë°¥", "ëˆê¹ŒìŠ¤",
        "í–„ë²„ê±°", "ë² ì´ê¸€", "ì¿ í‚¤", "í¬ë¡œí”Œ", "í˜¸ë–¡",
        "ê³ êµ¬ë§ˆë§›íƒ•", "ë‹¨í˜¸ë°•ìŠ¤í”„", "ê°ìíŠ€ê¹€", "ì¹˜ì¦ˆì¼€ì´í¬", "ìƒŒë“œìœ„ì¹˜", "ë¸Œë¼ìš°ë‹ˆ",
        "ì¹´ìŠ¤í…Œë¼", "ìš°ë™", "ë¦¬ì¡°ë˜", "ê¹€ë°¥", "ì§œì¥ë©´", "ë¼ìëƒ"
    ],
    'ê¸ˆ(é‡‘)': [
        "ì¹˜í‚¨", "í›„ë¼ì´ë“œì¹˜í‚¨", "ê°„ì¥ì¹˜í‚¨", "ë‹­ë°±ìˆ™", "ì˜¤ë¦¬ë°±ìˆ™", "ìˆœëŒ€êµ­",
        "ìˆœë‘ë¶€", "ë‘ë¶€ì¡°ë¦¼", "ê³„ë€ì°œ", "ê³„ë€êµ­", "ì–´ë¬µíƒ•", "ë¬´êµ­",
        "ì½©ë‚˜ë¬¼êµ­ë°¥", "ìƒì„ ê¹ŒìŠ¤", "ë‘ë¶€êµ¬ì´", "ë„ê°€ë‹ˆíƒ•", "ë‹­ì£½", "í°ì£½",
        "ìœ ë¦°ê¸°", "ì¹˜í‚¨ì»¤í‹€ë¦¿", "í¬ë¦¼ìš°ë™", "ì˜¤ì§•ì–´ìˆœëŒ€", "ì–‘íŒŒíŠ€ê¹€", "ëª…ë€íŒŒìŠ¤íƒ€"
    ],
    'ìˆ˜(æ°´)': [
        "ì´ˆë°¥", "ë¬¼íšŒ", "í•´ë¬¼íŒŒìŠ¤íƒ€", "í•´ë¬¼ë³¶ìŒë°¥", "í•´ë¬¼ì°œ", "ì˜¤ì§•ì–´ë®ë°¥",
        "ê°„ì¥ê²Œì¥", "ìƒˆìš°ì¥", "ì¥ì–´ë®ë°¥", "êµ´êµ­ë°¥", "ì¡°ê°œêµ­", "í™í•©íƒ•",
        "ì§¬ë½•", "ìš°ë™", "ë¼ë©˜", "í”¼ì‰¬ì•¤ì¹©ìŠ¤", "í•´ë¬¼ë¦¬ì¡°ë˜", "ì—°ì–´ë®ë°¥",
        "ìƒˆìš°ë³¶ìŒë°¥", "íšŒë®ë°¥", "ì´ˆê³„êµ­ìˆ˜", "í•´ì¥êµ­", "í™í•©ìŠ¤íŒŒê²Œí‹°", "ë¯¸ì—­ëƒ‰êµ­",
        "ì˜¤ë…íƒ•", "ë¬¼ë§Œë‘", "í´ë¨ì°¨ìš°ë”", "í•´ë¬¼ëˆ„ë£½ì§€íƒ•", "í•´ì‚¼íƒ•", "ì•„ì‚¬ì´ë³¼"
    ],
}

# ì˜¤í–‰ë³„ ìŒì‹ ëª©ë¡ì—ì„œ ëœë¤ìœ¼ë¡œ countê°œë§Œí¼ë§Œ ë¬¸ìì—´ë¡œ ë°˜í™˜
def get_food_recommendations_for_ohaeng(oheng: str, count: int = 3) -> str:
    foods = OHAENG_FOOD_LISTS.get(oheng)
    recommended_foods = random.sample(foods, min(count, len(foods)))
    return ', '.join(recommended_foods)

def normalize_to_hangul(oheng_name: str) -> str:
    return re.sub(r'\([^)]*\)', '', oheng_name).strip()


# ì˜¤í–‰ë³„ ì¼ë°˜í™” ì„¤ëª…
OHAENG_DESCRIPTION = {
    "ëª©(æœ¨)": "ìƒí¼í•˜ê³  ì‹ ì„ í•œ ëŠë‚Œì˜ ìŒì‹, ì•¼ì±„ê°€ ë“¤ì–´ê°„ ê°€ë²¼ìš´ ë©”ë‰´",
    "í™”(ç«)": "ë§¤ì½¤í•˜ê±°ë‚˜ ìê·¹ì ì¸ ë§›ì˜ ìŒì‹",
    "í† (åœŸ)": "ë“ ë“ í•˜ê³  ì•ˆì •ê° ìˆëŠ” ìŒì‹",
    "ê¸ˆ(é‡‘)": "ê³ ì†Œí•˜ê³  ì§­ì§¤í•œ ë§›ì˜ ìŒì‹",
    "ìˆ˜(æ°´)": "ì‹œì›í•˜ê³  ì´‰ì´‰í•œ ëŠë‚Œì˜ ìŒì‹, êµ­ë¬¼ì´ë‚˜ ìŒë£Œë¥˜"
}

# ìƒì„¸ ì¶”ì²œ ë©”ì‹œì§€ ìƒì„± í•¨ìˆ˜
def generate_concise_advice(lacking_oheng: List[str], strong_oheng: List[str], control_oheng: List[str]) -> str:
    # í•œê¸€ ì´ë¦„ì„ í‚¤ë¡œ, ì „ì²´ ì˜¤í–‰ ì´ë¦„(í•œì í¬í•¨)ì„ ê°’ìœ¼ë¡œ í•˜ëŠ” ë§µ ìƒì„±
    unique_ohaeng_map = {}
    for oheng in control_oheng:
        hangul_name = normalize_to_hangul(oheng)
        if hangul_name and oheng in OHAENG_FOOD_LISTS: # ìœ íš¨í•œ í‚¤ì¸ì§€ í™•ì¸
            unique_ohaeng_map[hangul_name] = oheng
            
    unique_control_oheng = list(unique_ohaeng_map.values())
    control_oheng_str = 'ì™€ '.join(unique_control_oheng) 
    lacking_oheng_set = set(lacking_oheng)
    control_oheng_set = set(unique_control_oheng) 
    strong_oheng_str = 'ì™€ '.join(strong_oheng)
    lacking_oheng_str = 'ì™€ '.join(lacking_oheng)
    
    # 1. ë¶€ì¡± ì˜¤í–‰ ì¡°ì–¸
    lacking_advice = "" 
    if lacking_oheng: 
        lacking_parts = []
        for oheng in lacking_oheng:
            foods = get_food_recommendations_for_ohaeng(oheng) 
            description = OHAENG_DESCRIPTION.get(oheng, "")
            lacking_parts.append(f"{oheng} ê¸°ìš´ì´ ì•½í•˜ë‹ˆ {description}ì¸ {foods}ì„(ë¥¼) ì¶”ì²œí•´")
            
        lacking_foods_str = 'ê³¼ '.join(lacking_parts)
        # ì²« ë²ˆì§¸ ë¬¸ì¥: ë¶€ì¡± ì˜¤í–‰ ê¸°ìš´ ë³´ì¶© ì¡°ì–¸
        lacking_advice = lacking_foods_str + ". "
    
    
    # 2. ê³¼ë‹¤ ë° ì œì–´ ì˜¤í–‰
    control_advice = ""
    # ë¶€ì¡± ì˜¤í–‰ê³¼ ì œì–´ ì˜¤í–‰ì´ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸
    if strong_oheng and unique_control_oheng and control_oheng_set.issubset(lacking_oheng_set):
        # ê²¹ì¹˜ëŠ” ê²½ìš°
        control_advice = (
            f"íŠ¹íˆ, ë¶€ì¡±í•œ {lacking_oheng_str} ê¸°ìš´ì€ ê°•í•œ {strong_oheng_str}ì„ ì¡°ì ˆí•´ì£¼ëŠ” ë”± ë§ëŠ” ìƒê·¹ ì˜¤í–‰ì´ê¸°ë„ í•´! "
            f"ë”°ë¼ì„œ {lacking_oheng_str} ê¸°ìš´ì˜ ìŒì‹ì„ ë¨¹ìœ¼ë©´ ë¶€ì¡±í•œ ê¸°ìš´ë„ ì±„ìš°ê³ , ë„˜ì¹˜ëŠ” ê¸°ìš´ê¹Œì§€ ì¡ì„ ìˆ˜ ìˆì–´ ğŸ˜‰"
        )
    
    elif strong_oheng and unique_control_oheng:
        # ê²¹ì¹˜ì§€ ì•ŠëŠ” ê²½ìš°
        control_food_parts = []
        for oheng in unique_control_oheng: 
            foods = get_food_recommendations_for_ohaeng(oheng)
            control_food_parts.append(foods)
        control_foods_str = ', '.join(control_food_parts)
        prefix = "ê·¸ë¦¬ê³  " if lacking_advice else "" 
        control_advice = (
            f"{prefix}ê°•í•œ {strong_oheng_str} ê¸°ìš´ì€ {control_oheng_str} ê¸°ìš´ì´ ëˆŒëŸ¬ì¤„ ìˆ˜ ìˆì–´. "
            f" ê¸°ìš´ë“¤ì´ ê· í˜•ì„ ì´ë£¨ê²Œ í•´ ì¤„ {control_foods_str}ì„ ì¶”ì²œí•´."
        )

    # 3. ìµœì¢… ë©”ì‹œì§€ ì¡°í•©
    final_message = lacking_advice + control_advice + "<br>ì—¬ê¸°ì„œ ë¨¹ê³  ì‹¶ì€ ë©”ë‰´ í•˜ë‚˜ ê³ ë¥´ë©´ ì‹ë‹¹ê¹Œì§€ ë°”ë¡œ ì¶”ì²œí•´ì¤„ê²Œ!"
    return final_message

# ì²« ë©”ì‹œì§€ ìƒì„± - ì˜¤í–‰ ê¸°ë°˜ ìƒì„¸ ë©”ì‹œì§€ë§Œ
async def get_initial_chat_message(uid: str, db: Session) -> str:
    # ì‚¬ì£¼ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    lacking_oheng, strong_oheng_db, oheng_type, oheng_scores = await _get_oheng_analysis_data(uid, db)
    
    # ë©”ì‹œì§€ ìƒì„± ë¡œì§ (strong_ohengs ì •ë³´ë¥¼ ê°€ì ¸ì˜´)
    headline, advice, recommended_ohengs_weights, control_ohengs, strong_ohengs = define_oheng_messages(lacking_oheng, strong_oheng_db, oheng_type)
    
    initial_message = generate_concise_advice(
        lacking_oheng=lacking_oheng, 
        strong_oheng=strong_ohengs, 
        control_oheng=control_ohengs 
    )
    
    return initial_message

MAX_MESSAGES = 10  # ìµœê·¼ ëŒ€í™” 10ê°œë§Œ ê¸°ì–µ

# ìµœê·¼ ëŒ€í™” 10ê°œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
def build_conversation_history(db: Session, chatroom_id: int) -> str:
    recent_messages = (
        db.query(ChatMessage)
        .filter(ChatMessage.room_id == chatroom_id)
        .order_by(ChatMessage.timestamp.desc())
        .limit(MAX_MESSAGES)
        .all()
    )
    recent_messages.reverse()  # ì‹œê°„ìˆœ ì •ë ¬

    conversation_history = ""
    for msg in recent_messages:
        role = "ì‚¬ìš©ì" if msg.role == "user" else "ë´‡"
        conversation_history += f"{msg.content}\n"
    return conversation_history

# ìµœê·¼ ë©”ì‹œì§€ì—ì„œ ì¶”ì²œí•œ ë©”ë‰´ ëª©ë¡ ë°˜í™˜
def get_latest_recommended_foods(db: Session, chatroom_id: int) -> List[str]:
    latest_bot_messages = (
        db.query(ChatMessage) 
        .filter(ChatMessage.room_id == chatroom_id, ChatMessage.role == "assistant")
        .order_by(ChatMessage.timestamp.desc())
        .limit(5)
        .all()
    )

    pattern_rule = re.compile(r"ê·¸ëŸ¬ë©´\s+(.*)\s+ì¤‘\s+í•˜ë‚˜ëŠ”\s+ì–´ë•Œ\?")
    food_ohaeng_recommendation_prefix = r"(.*ê¸°ìš´ì˜\s+ìŒì‹\s+|ë”°ë¼ì„œ\s+.*ê¸°ìš´ì„\s+ì±„ìš¸\s+ìˆ˜\s+ìˆëŠ”\s+)"
    pattern_ohaeng_recommendation = re.compile(food_ohaeng_recommendation_prefix + r"(.*)ì„\s*\(ë¥¼\)\s*ì¶”ì²œí•´\.")
    
    for msg in latest_bot_messages:
        content = msg.content.strip()
        
        # 1. ê·œì¹™ 2 (ìƒˆë¡œìš´ ë©”ë‰´ 3ê°€ì§€ ì¶”ì²œ) íŒ¨í„´ í™•ì¸
        match_rule = pattern_rule.search(content)
        if match_rule:
            food_list_str = match_rule.group(1).strip()
            return [f.strip() for f in food_list_str.split(',')]

        # 2. ì´ˆê¸° ì˜¤í–‰ ê¸°ë°˜ ì¶”ì²œ íŒ¨í„´ í™•ì¸
        match_recommendation = pattern_ohaeng_recommendation.search(content)
        if match_recommendation:
            food_list_str = match_recommendation.group(2).strip()
            return [f.strip() for f in food_list_str.split(',')]
            
    # ì ì ˆí•œ ë©”ë‰´ ëª©ë¡ì„ ì°¾ì§€ ëª»í–ˆë‹¤ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    return []

# ìœ ì‚¬ë„ ê²€ìƒ‰ - ì‹ë‹¹ ì •ë³´ ê²€ìƒ‰ ë° ì¶”ì²œ í•¨ìˆ˜
def search_and_recommend_restaurants(menu_name: str, db: Session):
    # 1. ChromaDB ì—°ê²°
    embeddings = get_embeddings()
    chroma_client = get_chroma_client()

    vectorstore_restaurants = Chroma(
        client=chroma_client,
        collection_name=COLLECTION_NAME_RESTAURANTS,
        embedding_function=embeddings
    )

    search_query = f"'{menu_name}' ë©”ë‰´ë¥¼ íŒë§¤í•˜ëŠ” ë§›ì§‘ ì‹ë‹¹"

    # 2. ìœ ì‚¬ë„ ê²€ìƒ‰
    try:
        restaurant_docs = vectorstore_restaurants.similarity_search(search_query, k=10)
    except Exception as e:
        print(f"Chroma ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

        return {
            "initial_message": "ì‹ë‹¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´.",
            "restaurants": [],
            "final_message": "ë‹¤ë¥¸ ë©”ë‰´ë„ ì¶”ì²œí•´ì¤„ê¹Œ?",
            "count": 0
        }

    # 3. ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ
    if not restaurant_docs:
        return {
            "initial_message": f"ì•„ì‰½ê²Œë„ **{menu_name}** ë©”ë‰´ë¥¼ íŒŒëŠ” ì‹ë‹¹ì„ ì°¾ì§€ ëª»í–ˆì–´.",
            "restaurants": [],
            "final_message": "ë‹¤ë¥¸ ë©”ë‰´ë„ ì¶”ì²œí•´ì¤„ê¹Œ?",
            "count": 0
        }

    # 4. 3ê°œ í•„í„°ë§
    validated_restaurants = []
    for doc in restaurant_docs:
        content = doc.page_content.strip()
        menu_snippet = doc.metadata.get("menu", "")

        if menu_name in content or menu_name in menu_snippet:
            validated_restaurants.append(doc)
            if len(validated_restaurants) >= 3:
                break

    # í•„í„° í›„ ì—†ìŒ
    if not validated_restaurants:
        return {
            "initial_message": f"ì•„ì‰½ê²Œë„ **{menu_name}** ë©”ë‰´ë¥¼ íŒŒëŠ” ì‹ë‹¹ì„ ì°¾ì§€ ëª»í–ˆì–´.",
            "restaurants": [],
            "final_message": "ë‹¤ë¥¸ ë©”ë‰´ë„ ì¶”ì²œí•´ì¤„ê¹Œ?",
            "count": 0
        }

    # 5. ì‹ë‹¹ IDë¡œ MySQL ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    restaurant_ids = [doc.metadata.get("restaurant_id") for doc in validated_restaurants]
    valid_ids = [id for id in restaurant_ids if id is not None]

    mysql_restaurants = db.query(Restaurant).filter(Restaurant.id.in_(valid_ids)).all()
    id_to_mysql_restaurant = {r.id: r for r in mysql_restaurants}

    # 6. ê²°ê³¼ ì •ì œ
    restaurant_data_list = []

    for doc in validated_restaurants[:5]:
        metadata = doc.metadata
        restaurant_id = metadata.get("restaurant_id")

        mysql_data = id_to_mysql_restaurant.get(restaurant_id)
        image_url = None

        # ì´ë¯¸ì§€ ì²˜ë¦¬
        if mysql_data and mysql_data.image:
            image_links = mysql_data.image.split(',')
            first_link = image_links[0].strip()

            if first_link.startswith(("'", '"')) and first_link.endswith(("'", '"')):
                first_link = first_link[1:-1]

            if first_link:
                image_url = first_link

        menu_snippet = metadata.get("menu", "ë©”ë‰´ ì •ë³´ ì—†ìŒ").split(', ')[:3]

        restaurant_data_list.append({
            "name": metadata.get("place_name", mysql_data.name if mysql_data else "ì´ë¦„ ì—†ìŒ"),
            "address": metadata.get("road_address_name", mysql_data.address if mysql_data else "ì£¼ì†Œ ì—†ìŒ"),
            "category": metadata.get("category_group_name", mysql_data.category if mysql_data else "ì¹´í…Œê³ ë¦¬ ì—†ìŒ"),
            "menu_snippet": menu_snippet,
            "image_url": image_url,
            "id": restaurant_id
        })

    # 7. ìµœì¢… ë°˜í™˜ payload
    final_payload = {
        "initial_message": f"ê·¸ëŸ¬ë©´ **{menu_name}**ì„(ë¥¼) íŒŒëŠ” ì‹ë‹¹ì„ ì¶”ì²œí•´ì¤„ê²Œ! ğŸ˜‹",
        "restaurants": restaurant_data_list,
        "final_message": "ë‹¤ë¥¸ í–‰ìš´ì˜ ë§›ì§‘ë„ ì¶”ì²œí•´ì¤„ê¹Œ?",
        "count": len(restaurant_data_list)
    }

    return final_payload


# ë‹¨ì²´ ì±„íŒ…ì—ì„œ ì‚¬ìš©ì ë©”ì‹œì§€ê°€ ë©”ë‰´ ì¶”ì²œ ìš”ì²­ì¸ì§€ ê°ì§€í•˜ëŠ” í•¨ìˆ˜
def is_initial_recommendation_request(user_message: str, conversation_history: str) -> bool:
    # ëŒ€í™” ê¸°ë¡ì—ì„œ ë´‡ì˜ ìƒì„¸ ì¶”ì²œ ë©”ì‹œì§€ íŒ¨í„´ í™•ì¸
    has_bot_recommendation = bool(
        re.search(r"ê¸°ìš´ì´ ì•½í•˜ë‹ˆ|ê¸°ìš´ì€.*ì¡°ì ˆí•´ì£¼ëŠ”|ê¸°ìš´ìœ¼ë¡œ ëˆŒëŸ¬ì£¼ë©´", conversation_history)
    )
    
    # ë´‡ì˜ ì¶”ì²œ ë©”ì‹œì§€ê°€ ìˆë‹¤ë©´ return
    if has_bot_recommendation:
        return False
    
    # ì¶”ì²œ ê´€ë ¨ í‚¤ì›Œë“œ
    recommendation_keywords = [
        "ê³¨ë¼", "ì¶”ì²œ", "ë­ ë¨¹", "ë­˜ ë¨¹", "ë¨¹ì„ê±°", "ë¨¹ì„ ê±°",
        #"ì ì‹¬", "ì €ë…", "ì•„ì¹¨", "ì‹ì‚¬", "ë§›ì§‘", "ë©”ë‰´", "ìŒì‹",
    ]
    
    # ì‚¬ìš©ìì˜ ë©”ì‹œì§€ì— ì¶”ì²œ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
    user_message_lower = user_message.lower()
    return any(keyword in user_message_lower for keyword in recommendation_keywords)


# llm í˜¸ì¶œ ë° ì‘ë‹µ ë°˜í™˜
def generate_llm_response(conversation_history: str, user_message: str, current_recommended_foods: List[str]) -> str:
    # ì§€ê¸ˆê¹Œì§€ ì¶”ì²œí•œ ë©”ë‰´ ëª©ë¡ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
    current_foods_str = ', '.join(current_recommended_foods)
    print(f"[DEBUG] current_recommended_foods: {current_foods_str}")

    prompt = f"""
    ë„ˆëŠ” ì˜¤ëŠ˜ì˜ ìš´ì„¸ì™€ ì˜¤í–‰ ê¸°ìš´ì— ë§ì¶° ìŒì‹ì„ ì¶”ì²œí•´ì£¼ëŠ” ì±—ë´‡ 'ë°¥í’€ì´'ì•¼. 
    ë„ˆì˜ ëª©í‘œëŠ” ì‚¬ìš©ìì˜ ìš´ì„¸ì— ë¶€ì¡±í•œ ì˜¤í–‰ ê¸°ìš´ì„ ì±„ì›Œì¤„ ìˆ˜ ìˆëŠ” ìŒì‹ì„ ì¶”ì²œí•˜ëŠ” ê±°ì•¼. 
    ì²« ì¸ì‚¬ëŠ” ì ˆëŒ€ ë°˜ë³µê¸ˆì§€. ë¬¸ì¥ì€ ê°„ê²°í•˜ê²Œ 
    
    ì‚¬ìš©ìì˜ ì…ë ¥ ë©”ì‹œì§€ì—ì„œ '@ë°¥í’€' ë©˜ì…˜ íƒœê·¸ëŠ” ì´ë¯¸ ì œê±°ëœ ìƒíƒœì´ë‹ˆ, '@ë°¥í’€' ë©˜ì…˜ì„ ì–¸ê¸‰í•˜ì§€ ì•Šê³  ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•˜ë©´ ë¼.
    
    [ê·œì¹™]
    1. ë©”ë‰´ ì§ì ‘ ì–¸ê¸‰ ì‹œ (ìš°ì„ ìˆœìœ„ 2)
    ì‚¬ìš©ìê°€ íŠ¹ì • ìŒì‹ ì´ë¦„ì„ ì§ì ‘ ì–¸ê¸‰í•˜ë©´  
    ì¦‰ì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•œë‹¤:
    [MENU_SELECTED:ë©”ë‰´ëª…]
    ê·¸ ì™¸ ì–´ë–¤ ë¬¸ì¥ë„ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ì•ŠëŠ”ë‹¤.
    
    2. ê¸ì • ë°˜ì‘ ì‹œ (ìš°ì„ ìˆœìœ„ 3)
    ì‚¬ìš©ìê°€ "ì¢‹ì•„", "ì¢‹ë„¤", "ì˜¤ì¼€ì´", "ã…‡ã…‹", "ë‹¤ ì¢‹ì•„"ë“± ê¸ì • í‘œí˜„ì„ ì‚¬ìš©í–ˆê³ ,
    íŠ¹ì • ë©”ë‰´ë¥¼ ì§ì ‘ ì–¸ê¸‰í•˜ì§€ ì•Šì•˜ë‹¤ë©´,
    â†’ ë°©ê¸ˆ ì¶”ì²œëœ ë©”ë‰´ ì „ì²´ë¥¼ ì„ íƒí•œ ê²ƒìœ¼ë¡œ ê°„ì£¼í•œë‹¤.

    ì´ ê²½ìš° ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•œë‹¤:
    [MENU_SELECTED_ALL:ë©”ë‰´1, ë©”ë‰´2, ë©”ë‰´3]
    
    3. ë‹¤ë¥¸ ë©”ë‰´ ìš”ì²­ ì‹œ (ìš°ì„ ìˆœìœ„ 4)
    ì‚¬ìš©ìê°€ "ë‹¤ë¥¸ ë©”ë‰´", "ë‹¤ë¥¸ ê±°", "~ë¹¼ê³ ", "ë³„ë¡œì•¼", 
    "ì•ˆ ë•¡ê²¨", "ë°”ê¿”ì¤˜" ë“± ì¶”ì²œ ê±°ì ˆì˜ë„ê°€ ë³´ì´ë©´ 

    â†’ ì§ì „ ë©”ë‰´ 3ê°œëŠ” ì ˆëŒ€ ë‹¤ì‹œ ì¶”ì²œí•˜ì§€ ì•ŠëŠ”ë‹¤.
    â†’ ì™„ì „íˆ ìƒˆë¡œìš´ ë©”ë‰´ 3ê°œë¥¼ ì¶”ì²œí•œë‹¤.
    
    4. ìŒì‹ê³¼ ë¬´ê´€í•œ ì¼ë°˜ ëŒ€í™” (ìš°ì„ ìˆœìœ„ 1)
    ì‚¬ìš©ìê°€ ë©”ë‰´ ì¶”ì²œ í˜¹ì€ ì‹ë‹¹ ì¶”ì²œì´ ì•„ë‹Œ ë¬´ê´€í•œ ë§ì„ í•˜ë©´
    ìŒì‹ ì¶”ì²œ ëŒ€í™”ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ìœ ë„

    ì´ì „ ëŒ€í™”:
    {conversation_history}
    
    ì‚¬ìš©ì:{user_message}
    
    """

    response = client.models.generate_content(
        model=model_name,
        contents=[prompt],
        config=types.GenerateContentConfig(temperature=0.7)
    )

    llm_response_text = response.text.strip()
        
    return llm_response_text